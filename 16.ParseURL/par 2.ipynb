{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Company XYZ is an Online Travel Agent site, such as Expedia, Booking.com, etc.\n",
    "\n",
    "They haven't invested in data science yet and all the data they have about user searches are simply stored in the URLs generated when users search for a hotel. If you are not familiar with URLs, you can run a search on any OTA site and see how all search parameters are present in the URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "* [Answer question 1](#Answer-question-1)\n",
    "* [Answer question 2](#Answer-question-2)\n",
    "* [Answer question 3](#Answer-question-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer question 1\n",
    "<span style='color:blue'>Create a clean data set where each column is a Ô¨Åeld in the URL, each row is a given search and the cells are the corresponding URL values.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constant definition\n",
    "Site = 'http://www.mysearchforhotels.com/shop/hotelsearch?'\n",
    "LenSite = len(Site)\n",
    "\n",
    "ParamPrefix = 'hotel.'\n",
    "LenParaPrefix = len(ParamPrefix)\n",
    "\n",
    "Separator = ', '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_url(url):\n",
    "    \"\"\"\n",
    "    input: a url string\n",
    "    output: a dictionary which contains parameter name and its value\n",
    "    \"\"\"\n",
    "    # remove common prefix\n",
    "    assert url[LenSite-1] == '?'\n",
    "    segments = url[LenSite:].split('&')\n",
    "\n",
    "    params = {}\n",
    "    for segment in segments:\n",
    "        kvpairs = segment.split('=')\n",
    "        assert len(kvpairs) == 2\n",
    "\n",
    "        k = kvpairs[0]\n",
    "        # remove common prefix\n",
    "        assert k[LenParaPrefix-1] == '.'\n",
    "        k = k[LenParaPrefix:]\n",
    "\n",
    "        if k in params:\n",
    "            print \"'{}' has already existed in search\".format(k)\n",
    "            params[k] = params[k] + Separator +kvpairs[1]\n",
    "        else:\n",
    "            params[k] = kvpairs[1]\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_parse():\n",
    "    succ_urls = []\n",
    "    fail_urls = []\n",
    "    with open(\"url_list.txt\",'rt') as inf:\n",
    "        for index,line in enumerate(inf):\n",
    "            try:\n",
    "                url = parse_url(line.strip())\n",
    "                succ_urls.append(url)\n",
    "            except:\n",
    "                fail_urls.append(line)\n",
    "                print \"failed to parse: {}\".format(line)\n",
    "\n",
    "            # if index%1000 ==0: print '{} lines parsed'.format(index)\n",
    "\n",
    "    print \"************ ALL DONE ************\"\n",
    "    return succ_urls,fail_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'amenities' has already existed in search\n",
      "'amenities' has already existed in search\n",
      "'amenities' has already existed in search\n",
      "'amenities' has already existed in search\n",
      "'amenities' has already existed in search\n",
      "************ ALL DONE ************\n"
     ]
    }
   ],
   "source": [
    "succ_urls,fail_urls = load_parse()\n",
    "assert len(fail_urls) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert into DataFrame\n",
    "urls = pd.DataFrame(succ_urls)\n",
    "\n",
    "# clean\n",
    "urls['checkin'] = pd.to_datetime(urls.checkin)\n",
    "urls['checkout'] = pd.to_datetime(urls.checkout)\n",
    "urls[\"children\"].fillna(0,inplace=True)\n",
    "urls['city'] = urls.city.str.replace('+',' ')\n",
    "urls['search_page'] = urls.search_page.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adults</th>\n",
       "      <th>amenities</th>\n",
       "      <th>checkin</th>\n",
       "      <th>checkout</th>\n",
       "      <th>children</th>\n",
       "      <th>city</th>\n",
       "      <th>couponCode</th>\n",
       "      <th>customMaximumPriceFilter</th>\n",
       "      <th>customMinimumPriceFilter</th>\n",
       "      <th>freeCancellation</th>\n",
       "      <th>max_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>search_page</th>\n",
       "      <th>stars_1</th>\n",
       "      <th>stars_2</th>\n",
       "      <th>stars_3</th>\n",
       "      <th>stars_4</th>\n",
       "      <th>stars_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65655</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>2015-09-14</td>\n",
       "      <td>0</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-27</td>\n",
       "      <td>2015-09-29</td>\n",
       "      <td>0</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>2015-09-20</td>\n",
       "      <td>0</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9012</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-21</td>\n",
       "      <td>2015-09-22</td>\n",
       "      <td>0</td>\n",
       "      <td>New York, NY, United States</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      adults amenities    checkin   checkout children  \\\n",
       "65655      2       NaN 2015-08-31 2015-09-01        0   \n",
       "19991      2       NaN 2015-09-01 2015-09-14        0   \n",
       "224        3       NaN 2015-09-27 2015-09-29        0   \n",
       "331        3       NaN 2015-09-13 2015-09-20        0   \n",
       "9012       2       NaN 2015-09-21 2015-09-22        0   \n",
       "\n",
       "                              city couponCode customMaximumPriceFilter  \\\n",
       "65655       London, United Kingdom        NaN                      225   \n",
       "19991       London, United Kingdom        NaN                      125   \n",
       "224         London, United Kingdom        NaN                      NaN   \n",
       "331         London, United Kingdom        NaN                      225   \n",
       "9012   New York, NY, United States        yes                      NaN   \n",
       "\n",
       "      customMinimumPriceFilter freeCancellation max_score min_score  \\\n",
       "65655                      NaN              NaN       NaN       NaN   \n",
       "19991                      NaN              NaN       NaN         4   \n",
       "224                        NaN              yes       NaN         5   \n",
       "331                        NaN              NaN       NaN         5   \n",
       "9012                       NaN              NaN       NaN       NaN   \n",
       "\n",
       "       search_page stars_1 stars_2 stars_3 stars_4 stars_5  \n",
       "65655            1     NaN     NaN     NaN     yes     NaN  \n",
       "19991            1     NaN     NaN     NaN     NaN     NaN  \n",
       "224              1     NaN     yes     NaN     NaN     NaN  \n",
       "331              1     NaN     NaN     NaN     NaN     NaN  \n",
       "9012             4     NaN     NaN     yes     NaN     NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls.sample(5)#glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urls.to_csv(\"urls.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer question 2\n",
    "<span style='color:blue'>For each search query, how many amenities were selected?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    76973\n",
       "True       704\n",
       "Name: amenities, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.notnull(urls.amenities).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** most of the search doesn't specify 'amenities'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "internet                272\n",
       "yes_smoking             170\n",
       "shuttle                 111\n",
       "yes_pet                  85\n",
       "breakfast                39\n",
       "lounge                   22\n",
       "yes_smoking, yes_pet      4\n",
       "breakfast, yes_pet        1\n",
       "Name: amenities, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls.amenities.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** so each search only contains one amenities, it seems the website doesn't allow include multiple amenities in the search. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amenities_cnts = urls.amenities.map(lambda s: 0 if pd.isnull(s) else len(s.split(Separator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    76973\n",
       "1      699\n",
       "2        5\n",
       "Name: amenities, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amenities_cnts.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer question 3\n",
    "<span style='color:blue'>Often, to measure the quality of a search algorithm, data scientists use some metric based on how often users click on the second page, third page, and so on. The idea here is that a great search algorithm should return all interesting results on the Ô¨Årst page and never force users to visit the other pages (how often do you click on the second page results when you search on Google? Almost never, right?).</span>\n",
    "\n",
    "<span style='color:blue'>Create a metric based on the above idea and Ô¨Ånd the city with the worst search algorithm.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     50000\n",
       "2     11637\n",
       "3      5864\n",
       "4      3635\n",
       "5      2422\n",
       "6      1636\n",
       "7      1114\n",
       "8       740\n",
       "9       436\n",
       "10      193\n",
       "Name: search_page, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls.search_page.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>London, United Kingdom</th>\n",
       "      <td>0.526588</td>\n",
       "      <td>0.187398</td>\n",
       "      <td>0.102502</td>\n",
       "      <td>0.065329</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.030152</td>\n",
       "      <td>0.020315</td>\n",
       "      <td>0.012973</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.003172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York, NY, United States</th>\n",
       "      <td>0.557616</td>\n",
       "      <td>0.181357</td>\n",
       "      <td>0.094575</td>\n",
       "      <td>0.058808</td>\n",
       "      <td>0.038899</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.018173</td>\n",
       "      <td>0.012660</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.003539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hong Kong, Hong Kong</th>\n",
       "      <td>0.910826</td>\n",
       "      <td>0.064992</td>\n",
       "      <td>0.014254</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Francisco, California, United States</th>\n",
       "      <td>0.959285</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.004853</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                1         2         3   \\\n",
       "city                                                                     \n",
       "London, United Kingdom                    0.526588  0.187398  0.102502   \n",
       "New York, NY, United States               0.557616  0.181357  0.094575   \n",
       "Hong Kong, Hong Kong                      0.910826  0.064992  0.014254   \n",
       "San Francisco, California, United States  0.959285  0.033613  0.004853   \n",
       "\n",
       "                                                4         5         6   \\\n",
       "city                                                                     \n",
       "London, United Kingdom                    0.065329  0.044372  0.030152   \n",
       "New York, NY, United States               0.058808  0.038899  0.026443   \n",
       "Hong Kong, Hong Kong                      0.005260  0.002291  0.001103   \n",
       "San Francisco, California, United States  0.001420  0.000829       NaN   \n",
       "\n",
       "                                                7         8         9   \\\n",
       "city                                                                     \n",
       "London, United Kingdom                    0.020315  0.012973  0.007199   \n",
       "New York, NY, United States               0.018173  0.012660  0.007929   \n",
       "Hong Kong, Hong Kong                      0.000848  0.000339  0.000085   \n",
       "San Francisco, California, United States       NaN       NaN       NaN   \n",
       "\n",
       "                                                10  \n",
       "city                                                \n",
       "London, United Kingdom                    0.003172  \n",
       "New York, NY, United States               0.003539  \n",
       "Hong Kong, Hong Kong                           NaN  \n",
       "San Francisco, California, United States       NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls.groupby('city')['search_page'].apply(lambda s: s.value_counts(normalize=True)).unstack().sort_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** I will define a metric called 'first page ratio', which measures within all pages about a certain city, how many of them are on page 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def firstpage_ratio(s):\n",
    "    total = s.shape[0]\n",
    "    n_firstpage = (s == 1).sum()\n",
    "    return float(n_firstpage)/total\n",
    "\n",
    "city_page1_ratio = urls.groupby('city')['search_page'].agg(firstpage_ratio).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "London, United Kingdom                      0.526588\n",
       "New York, NY, United States                 0.557616\n",
       "Hong Kong, Hong Kong                        0.910826\n",
       "San Francisco, California, United States    0.959285\n",
       "Name: search_page, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_page1_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "according to above result, ** the city with worst search experience is London.**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
